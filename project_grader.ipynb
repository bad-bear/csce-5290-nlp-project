{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCE 5290 NLP Project\n",
    "\n",
    "## NLP Models Reviewed\n",
    "- BERT\n",
    "- Naive Bayes\n",
    "- N-Grams\n",
    "    - Unigram\n",
    "    - Bigram\n",
    "    - Trigram\n",
    "    - Quadgram\n",
    "- Other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import genism\n",
    "import sklearn\n",
    "import matplotlib\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords as sw\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(filename):\n",
    "    new_df = pd.read_csv(filename, sep='\\t')\n",
    "    return new_df\n",
    "\n",
    "file = 'C:\\Users\\zionj\\OneDrive\\Documents\\GitHub\\csce-5290-nlp-project\\raw_data\\data\\training_set_rel3.tsv' \n",
    "essay_df = import_data(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(panda_df):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(curr_df):\n",
    "    \n",
    "    num_of_uniq_words = 0\n",
    "    avg_of_uniq_words = 0\n",
    "    for row_essay in curr_df['essay']:\n",
    "        temp_list = row_essay.split(' ')\n",
    "        num_of_uniq_words = Counter(temp_list)\n",
    "        avg_of_uniq_words = avg_of_uniq_words + num_of_uniq_words\n",
    "    avg_of_uniq_words = avg_of_uniq_words / essay_df.shape[0]\n",
    "\n",
    "    \n",
    "    num_of_words = 0\n",
    "    avg_of_words = 0\n",
    "    for row_essay in curr_df['essay']:\n",
    "        temp_list = row_essay.split(' ')\n",
    "        num_of_words = len(temp_list)\n",
    "        avg_of_words = avg_of_words + num_of_words\n",
    "    avg_of_words = avg_of_words / essay_df.shape[0]\n",
    "    \n",
    "\n",
    "    num_of_filler_words = 0\n",
    "    avg_of_filler_words = 0\n",
    "    for row_essay in curr_df['essay']:\n",
    "        temp_tokens = word_tokenize(row_essay)\n",
    "        stopwords_x = [w for w in temp_tokens if w in sw.words('English')]\n",
    "        avg_of_filler_words = avg_of_filler_words + stopwords_x\n",
    "    avg_of_filler_words = avg_of_filler_words / curr_df.shape[0]\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERT():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_results():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
